{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielHolzwart/Question-Answering-with-roberta/blob/main/Question_Answering_with_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this workbook, we will try to extract information from a sample CV file. Instead of summarizaton, we will work with roberta question and answering model which has been trained on the SQuAD2 dataset2. Let's see how the model perfoms on this set. It could be that we will not get the desired results as the SQuAD2 dataset contains answers from *arcticles*, while a CV in general has bullet points."
      ],
      "metadata": {
        "id": "axuzkPP5uZk_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEXtUDeN1VG0",
        "outputId": "a1781aac-55be-43fd-cb65-dc6a62151f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyMUPDF is used to read in a pdf file and export a text which."
      ],
      "metadata": {
        "id": "oFlJDDySVzS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCcx8Oht1252",
        "outputId": "cd443775-7791-45c3-802f-d829836fe28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.24.10)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.10 in /usr/local/lib/python3.10/dist-packages (from pymupdf) (1.24.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utz-Yg5Y1V3a"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6gVQCLz1c0f"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "\n",
        "    #read in document\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    #declare empty string\n",
        "    text = \"\"\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc[page_num]\n",
        "        #add page to empty string\n",
        "        text += page.get_text()\n",
        "    doc.close()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read in CV sample file from google drive\n",
        "import os\n",
        "cv_path = os.getcwd() + '/drive/My Drive/2024-09-21 Question Answering with roberta'  + '/cvsamples.pdf'\n",
        "cv_text = extract_text_from_pdf(cv_path)"
      ],
      "metadata": {
        "id": "zK8y34taIP-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model can't process the whole CV input at once. Therefore, we must split it into chunks. The following functions does that and also implements a stride as chunks can have overlapping information."
      ],
      "metadata": {
        "id": "7aGACpH1rhJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_chunks(text, max_length=150, stride = 25):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for word in words:\n",
        "        #add current_chunk to chunk list if word threshold is triggered\n",
        "        if len(current_chunk) + len(word) + 1 > max_length:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            #set a stride of 25\n",
        "            current_chunk = current_chunk[-stride:]\n",
        "            current_chunk.extend([word])\n",
        "        else:\n",
        "            current_chunk.append(word)\n",
        "    #for the last remaining text of the document\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "izFH6vHLnKcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text_chunks = split_text_into_chunks(cv_text)\n",
        "print(len(cv_text_chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDZHeuv9nO_c",
        "outputId": "f7fd794a-d637-4c9e-a85e-126bd0477163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check whether the stride work as intended"
      ],
      "metadata": {
        "id": "BuquvH4_xTcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text_chunks[0].split()[-25:] == cv_text_chunks[1].split()[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0fLAHnBx24j",
        "outputId": "84e533ca-8950-48bf-94f0-b31729d930f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything works as intended. Now we can set up a question answering model from hugging face. The easiest way is via"
      ],
      "metadata": {
        "id": "s9W77qazy_lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "\n",
        "model = \"consciousAI/question-answering-roberta-base-s-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipe = pipeline(\"question-answering\", model=model,tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "JFjyqAA_qTxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04a6c21-05d4-4f1c-9583-a67ff4b033a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is Mike's profession?\"\n",
        "context =  \"Mike was born in August 1972 in Canada, always wanted to be a pilot and thus went to pilot school. However, he eventually realized that he is afraid of heights and became a handyman.\""
      ],
      "metadata": {
        "id": "Sgc-UOawq2Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(question=question, context=context, top_k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpKeadjUqXI6",
        "outputId": "946387e6-4872-4700-bd62-d14a6e212bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.41693350672721863,\n",
              "  'start': 173,\n",
              "  'end': 181,\n",
              "  'answer': 'handyman'},\n",
              " {'score': 0.09210065752267838, 'start': 62, 'end': 67, 'answer': 'pilot'},\n",
              " {'score': 0.02496851421892643,\n",
              "  'start': 171,\n",
              "  'end': 181,\n",
              "  'answer': 'a handyman'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First test is looking good. Now we can try to apply our model to the chunks from the CV file. The model will try to answer the question to every chunk of the model and we will pick out the answer with the highest score. The answer to the question of 'How many undergrade students did Juan Garcia take care of?' is 2."
      ],
      "metadata": {
        "id": "sYWFqf0v2oBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How many undergrade students did Juan Garcia take care of?\"\n",
        "output_scores = []\n",
        "answers = []\n",
        "for chunks in cv_text_chunks:\n",
        "    output = pipe(question=question, context= chunks)\n",
        "    output_scores.append(output[\"score\"])\n",
        "    answers.append(output[\"answer\"])\n",
        "    print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wJj_TzT3ZsE",
        "outputId": "dcef946f-ba5c-4c88-ca2f-02fd268bf54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.00012995986617170274, 'start': 0, 'end': 3, 'answer': '217'}\n",
            "{'score': 1.3816425781243424e-10, 'start': 636, 'end': 637, 'answer': '.'}\n",
            "{'score': 1.8613463548255993e-10, 'start': 496, 'end': 503, 'answer': '06/2014'}\n",
            "{'score': 7.08324371379021e-11, 'start': 172, 'end': 173, 'answer': '.'}\n",
            "{'score': 8.089430514335305e-11, 'start': 366, 'end': 367, 'answer': '.'}\n",
            "{'score': 4.136669062848597e-10, 'start': 1015, 'end': 1016, 'answer': '3'}\n",
            "{'score': 1.1071007999241544e-10, 'start': 197, 'end': 198, 'answer': '.'}\n",
            "{'score': 1.0605149397546754e-10, 'start': 571, 'end': 572, 'answer': '.'}\n",
            "{'score': 6.384082151811299e-11, 'start': 389, 'end': 390, 'answer': '.'}\n",
            "{'score': 1.010520556121719e-10, 'start': 974, 'end': 976, 'answer': '.”'}\n",
            "{'score': 3.3165772350685074e-09, 'start': 202, 'end': 206, 'answer': '20xx'}\n",
            "{'score': 7.596036688539698e-09, 'start': 84, 'end': 88, 'answer': '20xx'}\n",
            "{'score': 2.993368608539271e-10, 'start': 744, 'end': 795, 'answer': '. \\uf0b7 Edited copy for publication on a monthly basis.'}\n",
            "{'score': 9.750739798919383e-11, 'start': 467, 'end': 468, 'answer': '.'}\n",
            "{'score': 0.01036396250128746, 'start': 557, 'end': 561, 'answer': '4567'}\n",
            "{'score': 4.881313202531601e-07, 'start': 1005, 'end': 1008, 'answer': 'two'}\n",
            "{'score': 6.82604149915278e-05, 'start': 581, 'end': 586, 'answer': '15-25'}\n",
            "{'score': 0.05405785143375397, 'start': 945, 'end': 948, 'answer': 'two'}\n",
            "{'score': 0.8707802295684814, 'start': 43, 'end': 46, 'answer': 'two'}\n",
            "{'score': 2.671255716624188e-10, 'start': 1008, 'end': 1036, 'answer': 'a group of minority children'}\n",
            "{'score': 0.1274404227733612, 'start': 779, 'end': 780, 'answer': '3'}\n",
            "{'score': 6.142141656395594e-11, 'start': 116, 'end': 117, 'answer': '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One observation is that the model output are in general numbers. This is to expect as the queston started with 'How many'. Let us pick out the 3 prediction with the highest score. Moreover, in most cases the score is extremly small and we only get an ouput because we forced the model to do so."
      ],
      "metadata": {
        "id": "WnkKn-B83jSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_position = sorted(enumerate(output_scores), key=lambda x: x[1], reverse=True)[:3]\n",
        "for position, scores in top_3_position:\n",
        "    print(f\"Answer: {answers[position]} - with score {scores} in chunk {position}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_j9fD_K6qt1",
        "outputId": "19145a46-0242-42cd-a8f7-1479c3ed75f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: two - with score 0.8707802295684814 in chunk 18\n",
            "Answer: 3 - with score 0.1274404227733612 in chunk 20\n",
            "Answer: two - with score 0.05405785143375397 in chunk 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like the model is fairly confident with Juan Garcia mentoring 2 students. It is interesting that answer 1 and 3 both have the value two and a quick check reveals that this is actually coming from the stride we implemented in the chunks"
      ],
      "metadata": {
        "id": "qLTxC3iJ8PLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text_chunks[17]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "mSbHnf9U3gA9",
        "outputId": "b792e92b-ef11-485e-832f-d0ebdd0c986a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'by Their Students. Spring 20XX - Present Instructor, Latino/a Culture Anthropology Department, University of Illinois \\uf0b7 Integrated multimedia approaches and used instructional technology to enhance pedagogical approach. \\uf0b7 Explained challenging concepts using planned lessons, assignments and targeted discussions for 75 freshmen and sophomore students. Spring - Fall 20XX Graduate Mentor, Illinois Summer Research Opportunities Program The Graduate College, University of Illinois \\uf0b7 Mentored two undergraduate students in data collection and analysis to visualize the properties of various geotechnical materials. \\uf0b7 Guided the students in preparation and presentation of research findings. Summer 20XX, 20XX CV SAMPLE 7 grad.illinois.edu/CareerDevelopment Juan Garcia, page 2 of 3 TEACHING AND MENTORING EXPERIENCE CONTINUED Graduate Mentor, Illinois Summer Research Opportunities Program The Graduate College, University of Illinois \\uf0b7 Mentored two undergraduate students in data collection and analysis to visualize the properties of various geotechnical materials. \\uf0b7 Guided the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text_chunks[18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "63euYGM49el7",
        "outputId": "7e16ee47-8195-4451-a41d-7c2a04672b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'College, University of Illinois \\uf0b7 Mentored two undergraduate students in data collection and analysis to visualize the properties of various geotechnical materials. \\uf0b7 Guided the students in preparation and presentation of research findings. Summer 20XX, 20XX HONORS AND AWARDS Fulbright Scholarship to pursue a PhD \\uf0b7 20 scholarships awarded in Argentina that year 20XX Flag Honor Guard Member \\uf0b7 Qualified by graduating with honors and ranking 4th among engineering majors at UNSJ 20XX GRANTS Granting Agency, “Title of Grant”, $00,000 20XX - 20XX PUBLICATIONS Garcia, J., other authors. (Year). Title. Journal, Volume (Issue), page numbers. doi:. Garcia, J., other authors. (in press). Title. Journal, Volume (Issue), page numbers. Garcia, J., other authors. (Year produced). Title. Manuscript submitted for publication. Garcia, J., other authors. (Year draft produced). Title. Manuscript in preparation. CONFERENCE PRESENTATIONS ORAL PRESENTATIONS Garcia, J., other authors. (Year, Month). Title.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is hard to say where score for the second best answer, 3, is coming from. Looking at the snippet below, the text cotain the name Juan Garcia, student activities and 'page 3 of 3. Thus the model somehow linked the 3 to the student. Nevertheless, the score for the 2nd answer is still 6 times lower than for the first."
      ],
      "metadata": {
        "id": "DuIdpYTD_P9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_text_chunks[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "jfrtpYpU6gHk",
        "outputId": "5b85f965-4cdd-49b6-aada-220f5ef12706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Illinois \\uf0b7 Participated in the organization of the Principal’s Scholars Program 20XX GEAR UP College Bound Summer Program, where a group of minority children from elementary and middle school visited the college to learn about different paths in engineering. \\uf0b7 Prepared a bridge design competition using popsicle sticks and glue, where the children demonstrated their skills and their creativity. July 20XX Student Assistant Office of International Student and Scholar Services (ISSS), University of Illinois \\uf0b7 Assisted with check-in procedures for incoming international students. \\uf0b7 Helped incoming international students with information on procedures and resources for their successful arrival on campus. July 20XX 8 grad.illinois.edu/CareerDevelopment Juan Garcia, page 3 of 3 TECHNICAL SKILLS \\uf0b7 Programming languages and mathematical packages: Matlab, Mathematica, C, C ++ \\uf0b7 Computer aided design/engineering: optical imaging, AutoCAD, Patran, Abaqus. \\uf0b7 Other: SPSS, Linux (openSUSE, Ubuntu), Mac OS, Windows OS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9f9wAb96z5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5iChFBjntnwQEu2h/zxRu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}